services:
  #######################################
  #  POSTGRESQL (para MLflow + Airflow)
  #######################################
  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - mlops_net

  ######################################################
  #  INIT AIRFLOW DATABASE (crea DB airflow en Postgres)
  ######################################################
  init-airflow-db:
    image: postgres:15
    depends_on:
      - postgres
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_HOST: postgres
    entrypoint: >
      bash -c "
      sleep 5 &&
      PGPASSWORD=$POSTGRES_PASSWORD psql -h $POSTGRES_HOST -U $POSTGRES_USER -tc \"SELECT 1 FROM pg_database WHERE datname = 'airflow';\" | grep -q 1 ||
      PGPASSWORD=$POSTGRES_PASSWORD psql -h $POSTGRES_HOST -U $POSTGRES_USER -c 'CREATE DATABASE airflow;'
      "
    networks:
      - mlops_net

  ##########################################
  #  MINIO (almacenamiento tipo S3 local)
  ##########################################
  minio:
    image: minio/minio:latest
    container_name: minio
    restart: always
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":${MINIO_CONSOLE_PORT}"
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - mlops_net

  ###################################
  # MLFLOW TRACKING SERVER
  ###################################
  mlflow:
    build: ./mlflow
    container_name: mlflow
    env_file: .env
    restart: always
    ports:
      - "5500:5000"
    command: >
      mlflow server
      --backend-store-uri ${MLFLOW_BACKEND_STORE_URI}
      --default-artifact-root ${MLFLOW_ARTIFACT_STORE_URI}
      --host 0.0.0.0
    environment:
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      MLFLOW_S3_ENDPOINT_URL: ${MINIO_ENDPOINT}
    networks:
      - mlops_net

  ###################################
  # AIRFLOW - Inicialización
  ###################################
  airflow-init:
    build: ./airflow
    container_name: airflow-init
    env_file: .env
    entrypoint: /bin/bash
    command:
      - -c
      - |
        echo " Esperando a que Postgres esté listo..."
        until pg_isready -h postgres -U mlflow -d airflow; do
          sleep 3
          echo "Aún no está listo..."
        done
        echo " Postgres está listo, inicializando Airflow..."
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins
        pip install --no-cache-dir -r /opt/airflow/requirements.txt
        airflow db migrate
        airflow users create \
          --username admin \
          --firstname Juan \
          --lastname Ruiz \
          --role Admin \
          --email admin@example.com \
          --password admin
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/requirements.txt:/opt/airflow/requirements.txt
      - ./data:/opt/airflow/data
    depends_on:
      - postgres
      - init-airflow-db
    networks:
      - mlops_net

  ###################################
  # AIRFLOW - Webserver
  ###################################
  airflow-webserver:
    build: ./airflow
    container_name: airflow-webserver
    env_file: .env
    restart: always
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    command: webserver
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
    networks:
      - mlops_net

  ###################################
  # AIRFLOW - Scheduler
  ###################################
  airflow-scheduler:
    build: ./airflow
    container_name: airflow-scheduler
    env_file: .env
    restart: always
    depends_on:
      - airflow-init
    command: scheduler
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data
    networks:
      - mlops_net

  ###################################
  # FASTAPI - Inferencia modelo
  ###################################
  diabetes-api:
    build:
      context: .                    
      dockerfile: ./api/Dockerfile 
    container_name: diabetes-api
    restart: always
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MODEL_NAME: diabetes_readmission_xgb
      MODEL_STAGE: Production
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      MLFLOW_S3_ENDPOINT_URL: ${MINIO_ENDPOINT}
    ports:
      - "8000:8000"
    depends_on:
      - mlflow
    networks:
      - mlops_net

###################################
# RED Y VOLUMENES
###################################
networks:
  mlops_net:
    driver: bridge

volumes:
  postgres_data:
  minio_data:
